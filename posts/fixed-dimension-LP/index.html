<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="googlebot" content="noindex">
    <title>Minimizing Sum of PWL Convex Functions</title>
    <link rel="stylesheet" href="../../css/fonts.css" />
    <link rel="stylesheet" href="../../css/default.css" />
    <link rel="stylesheet" href="../../css/pygentize.css" />
    <link rel="stylesheet" href="../../css/chao-theorems.css">
    <link rel="stylesheet" href="../../css/sidenotes.css">
    <script defer src="../../css/pangu.simple.js"></script>
    <script>
        // page title
        document.addEventListener("DOMContentLoaded", function () {
            const hostname = window.location.hostname;
            document.title = document.title + " | " + hostname;
        });

        // pangu
        document.addEventListener('DOMContentLoaded', () => {
            pangu.autoSpacingPage();
        });

        // mathjax
        MathJax = {
            options: {
                menuOptions: {
                    settings: {
                        enrich: false,        // true to enable semantic-enrichment
                        collapsible: false,   // true to enable collapsible math
                        speech: false,        // true to enable speech generation
                        braille: false,       // true to enable Braille generation
                        assistiveMml: false,  // true to enable assistive MathML
                    }
                },
                enableMenu: false
            },
            output: {
                font: 'mathjax-fira',
                fontPath: '/mathjax-fira-font'
            },
            tex: {
                macros: {
                    floor: ["{\\left\\lfloor #1 \\right\\rfloor}", 1],
                    ceil: ["{\\left\\lceil #1 \\right\\rceil}", 1],
                    set: ["{\\left\\{ #1 \\right\\}}", 1],
                    norm: ["{\\left\\| #1 \\right\\|}", 1],
                    F: "{\\mathbb F}",
                    R: "{\\mathbb R}",
                    C: "{\\mathbb C}",
                    Z: "{\\mathbb Z}",
                    e: "{\\varepsilon}",
                    mex: "\\mathop{\\operatorname{mex}}",
                    lcm: "\\mathop{\\operatorname{lcm}}",
                    dist: "\\mathop{\\operatorname{dist}}",
                    poly: "\\mathop{\\operatorname{poly}}",
                    polylog: "\\mathop{\\operatorname{polylog}}",
                    span: "\\mathop{\\operatorname{span}}",
                }
            }
        };
    </script>
    <script defer src="../../mathjax/tex-chtml.js"></script>

</head>

<body>
    <div class="navbar-space">
        
        <!-- A table of contents on the left side, but only for screens
                that are big enough -->
        <div id="contents-big">
            <p class="mini-header">Contents <a id="up-arrow" href="#">↑</a></p>
            <ul>
<li><a href="#the-problem-failed-attempts">the problem &amp; failed attempts</a></li>
<li><a href="#color-refinement-on-matrices">color refinement on matrices</a>
<ul>
<li><a href="#connections">connections</a></li>
<li><a href="#is-it-useful">is it useful?</a></li>
<li><a href="#reflection">reflection</a></li>
</ul></li>
</ul>
        </div>
        
    </div>
    <div class="text-space">
        <header class="no-print">
            <nav class="navbar">
                <a href="../../">Home</a>
                <div class="navright">
                    <a href="../../draft">Drafts</a>
                    <a href="../../about">About</a>
                </div>
            </nav>
        </header>

        <main role="main">
            <h1 class="pagetitle">Minimizing Sum of PWL Convex Functions</h1>
            <article>
    <section class="subtitle">
        
        
    </section>
    <section class="header">
        Posted on September 20, 2024
        
            by Yu Cong
        
    </section>
    <div class="info">
        
            Tags: <a title="All pages tagged 'alg'." href="../../tags/alg/index.html" rel="tag">alg</a>, <a title="All pages tagged 'optimization'." href="../../tags/optimization/index.html" rel="tag">optimization</a>, <a title="All pages tagged 'LP'." href="../../tags/LP/index.html" rel="tag">LP</a>
        
    </div>    
    <section>
        This is my note on low-dimension linear programming &amp; color
refinement algorithms.
<h1 data-number="1" id="the-problem-failed-attempts"><span class="header-section-number">1</span> the problem &amp; failed
attempts</h1>
<p></p>
In September I’m working on the following small problem,
<div id="probpwl" class="theorem-environment Problem" data-index="1" type="Problem" title="Minimizing the Sum of Piecewise Linear Convex Functions">
<span class="theorem-header"><span class="type">Problem</span><span class="index">1</span><span class="name">Minimizing the Sum of Piecewise
Linear Convex Functions</span></span>
<p></p>
Given <span class="math inline">\(n\)</span> piecewise linear convex
functions <span class="math inline">\(f_1,...,f_n:\R \to \R\)</span> of
total <span class="math inline">\(m\)</span> breakpoints, and <span class="math inline">\(n\)</span> linear functions <span class="math inline">\(a_i\cdot x-b_i:\R^d\to \R\)</span>, find <span class="math inline">\(\min_x \sum_i f_i(a_i\cdot x-b_i)\)</span>.
</div>
<p></p>
which is highly related to algorithms for linear programming in low
dimensions.
<p></p>
This can be solve in <span class="math inline">\(O(2^{2^d}(m+n))\)</span> through Megiddo’s
algorithm for multidimensional search problem. (see <a href="../../pdfs/LowdimLP-Megiddo.pdf">my slides</a>)
<p></p>
I want to show that for general piecewise linear convex functions in
<span class="math inline">\(\R^d\)</span>, <a href="#probpwl">my
problem</a> can be formulated as a <a href="https://en.wikipedia.org/wiki/LP-type_problem">LP-type</a> problem
with low combinatorial dimension.
<p></p>
A failed attempt is trying to write <span class="math inline">\(F=\sum_i
f_i\)</span>. However, there may be too many breakpoints on <span class="math inline">\(F\)</span>. (see <a href="../../posts/2024-09-16-piecewise-linear">a previous post</a>). Another
possible way is using some dimension reduction techniques <span class="citation" data-cites="grohe_dimension_2014">[<a href="#ref-grohe_dimension_2014" role="doc-biblioref">1</a>]</span>.
<h1 data-number="2" id="color-refinement-on-matrices"><span class="header-section-number">2</span> color refinement on matrices</h1>
<blockquote>
<p></p>
I do not have high expectation on this method, since I need to show that
color refinement indeed reduce the dimension from <span class="math inline">\(n+d\)</span> to <span class="math inline">\(d\)</span> and that the reduction can be done in
linear time.
</blockquote>
<p></p>
Given a initial coloring of vertices in a directed graph <span class="math inline">\(G=(V,A)\)</span>, we want to compute the
<em>coarsest regular congruent</em> coloring.
<p></p>
Colorings can be considered as equivalence relations on the vertices. An
equivalence relation <span class="math inline">\(R\)</span> on <span class="math inline">\(V\)</span> is <em>congruent</em> if for all <span class="math inline">\(u,v,w\in V\)</span>, [<span class="math inline">\((u,v)\in R\)</span> and <span class="math inline">\((v,w)\in A\)</span>] implies that [<span class="math inline">\(\exists v'\in V\)</span> such that <span class="math inline">\((v,v')\in A\)</span> and <span class="math inline">\((v',w)\in R\)</span>]. Note that this
coincides with the general <a href="https://en.wikipedia.org/wiki/Congruence_relation">definition of
congruence relation</a> in algebraic structures.(We can copy each vertex
#outdegree times to make <span class="math inline">\(A\)</span> an unary
operation.)
<p></p>
A coloring is <em>regular</em> if for any two vertices <span class="math inline">\(u,v\)</span>, the number of successors in each
color are the same. Consider two colorings <span class="math inline">\(C_1,C_2\)</span>. <span class="math inline">\(C_1\)</span> is a refinement of <span class="math inline">\(C_2\)</span>(or <span class="math inline">\(C_2\)</span> is coarser than <span class="math inline">\(C_1\)</span>) if for any two vertices having the
same color in <span class="math inline">\(C_1\)</span>, they have the
same color in <span class="math inline">\(C_2\)</span>.
<p></p>
<strong>Basic Lemma 1</strong> in <span class="citation" data-cites="cardon_partitioning_1982">[<a href="#ref-cardon_partitioning_1982" role="doc-biblioref">2</a>]</span>
shows that the problem above is equivalent to the description in <a href="https://en.wikipedia.org/wiki/Colour_refinement_algorithm">this
wiki page</a>.
<p></p>
The first quasilinear time algorithm for the color refinement problem on
graphs is given in <span class="citation" data-cites="cardon_partitioning_1982">[<a href="#ref-cardon_partitioning_1982" role="doc-biblioref">2</a>]</span>,
and later in <span class="citation" data-cites="paige_three_1987">[<a href="#ref-paige_three_1987" role="doc-biblioref">3</a>]</span>. It is
shown in <span class="citation" data-cites="berkholz_tightbound_2017">[<a href="#ref-berkholz_tightbound_2017" role="doc-biblioref">4</a>]</span>
that <span class="math inline">\(O((m+n)\log n)\)</span> is the best
possible running time. It is also shown in <span class="citation" data-cites="kiefer_et_alicalp20">[<a href="#ref-kiefer_et_alicalp20" role="doc-biblioref">5</a>]</span> that for any number of vertices there
exists a graph which requires at least <span class="math inline">\(n-2\)</span> iterations to reach a stable
coloring(note that the upperbound is <span class="math inline">\(n-1\)</span>). See <a href="https://www.lics.rwth-aachen.de/global/show_document.asp?id=aaaaaaaaabbtcqu">this</a>
for a nice survey on applications.
<h2 data-number="2.1" id="connections"><span class="header-section-number">2.1</span> connections</h2>
<h3 data-number="2.1.1" id="color-refinement-on-graphs-to-on-matrices"><span class="header-section-number">2.1.1</span> color refinement on graphs
<span class="math inline">\(\to\)</span> on matrices</h3>
<p></p>
Now we add edge weights on the directed graph. Suppose all arcs have
weight 1. One can see that a congruent and regular coloring requires
that two vertices have the same color iff for each color the total
weight of arcs going to vertices in that color are the same. Slightly
generalize this configuraton, we can consider arbitrary arc weights.
<p></p>
Now color refinement on matrices are almost the same as doing color
refinement on the incidence matrix of a weighted digraph. However, not
every matrix is square. For any matrix <span class="math inline">\(A\in
\R^{v\times w}\)</span>, we consider it as a bitartite graph <span class="math inline">\(G=(V\sqcup W,A)\)</span>, where <span class="math inline">\(|V|=v\)</span> and <span class="math inline">\(|W|=w\)</span>. Then <span class="math inline">\(A_{ij}=w(i, j)\)</span> if <span class="math inline">\((i, j)\)</span> is an arc in <span class="math inline">\(G\)</span> and 0 otherwise.
<h3 data-number="2.1.2" id="color-refinement-on-matrices-to-dimension-reduction-of-lps"><span class="header-section-number">2.1.2</span> color refinement on matrices
<span class="math inline">\(\to\)</span> dimension reduction of LPs</h3>
<p></p>
This part is not intuitive and complicated. I think the ESA 14 paper
<span class="citation" data-cites="grohe_dimension_2014">[<a href="#ref-grohe_dimension_2014" role="doc-biblioref">1</a>]</span> is
very concise (compared to the arxiv version), however still takes four
and a half pages to explain this part. So I will just briefly explain
the idea.
<p></p>
This connection is based on an important theorem, stating that the color
refinement of a matrix <span class="math inline">\(A\)</span> has strong
relation with the fractional automorphism of <span class="math inline">\(A\)</span>. To do the reduction, we first compute
a color refinement of <span class="math inline">\(A\)</span>. Based on
the partitions of columns and rows of <span class="math inline">\(A\)</span> in the color refinement(partition
matrices), we can conpute the <strong>factor matrix</strong> of <span class="math inline">\(A\)</span>, denoted by <span class="math inline">\([A]\)</span>, which is small than <span class="math inline">\(A\)</span>. Then finally, the authors proved a
reduction lemma, which shows that the optimal solution to factor matrix
of the entire LP(I don’t know the exact name, just the matrix one uses
in the simplex method) is a linear mapping of the optimal solution of
the original LP.
<h2 data-number="2.2" id="is-it-useful"><span class="header-section-number">2.2</span> is it useful?</h2>
<p></p>
The reduction looks clever and has a wide application. However, as far
as I know, it does nothing on my problem. I don’t think the matrix in my
problem is special enough to allow color refinement algorithms run in
linear time on it. Also color refinement does not necessarily partition
all <span class="math inline">\(f_i\)</span> columns in one part.
<code>¯\_(⊙︿⊙)_/¯</code>
<h2 data-number="2.3" id="reflection"><span class="header-section-number">2.3</span> reflection</h2>
<p></p>
Multidimensional search is harder than LP-type problems, this question
is no exception. Now there are three kinds of problems I am interested
in.
<ol type="1">
<li>Minimax parametric optimization</li>
<li>Multidimensional search problems</li>
<li>LP-type problems</li>
</ol>
<p></p>
What’s the connections among them?…
<div id="minmax" class="theorem-environment Definition" data-index="2" type="Definition" title="Minimax parametric optimization problem">
<span class="theorem-header"><span class="type">Definition</span><span class="index">2</span><span class="name">Minimax parametric optimization
problem</span></span>
<p></p>
Given a combinatorial maximization problem with a parameter. Find the
parameter value minimizing the weight of a solution to the combinatorial
maximization problem.
</div>
<div id="multisearch" class="theorem-environment Definition" data-index="3" type="Definition" title="Multidimensional search problem">
<span class="theorem-header"><span class="type">Definition</span><span class="index">3</span><span class="name">Multidimensional search
problem</span></span>
<p></p>
Given a set of hyperplanes <span class="math inline">\(\mathcal
H\)</span> in <span class="math inline">\(\R^d\)</span>, and an oracle
which answers the relative position of one hyperplane and a unknown
fixed point <span class="math inline">\(x^*\in \R^d\)</span>. Compute
the relative position of every hyperplane in <span class="math inline">\(\mathcal H\)</span> and <span class="math inline">\(x^*\)</span> with as small number of oracle calls
as possible.
</div>
<div id="lptype" class="theorem-environment Definition" data-index="4" type="Definition" title="LP-type problem">
<span class="theorem-header"><span class="type">Definition</span><span class="index">4</span><span class="name">LP-type problem</span></span>
<p></p>
Given a set <span class="math inline">\(S\)</span> and a function <span class="math inline">\(f\)</span> from <span class="math inline">\(S\)</span> to a totally ordered set. <span class="math inline">\(f\)</span> has to satisfy two properties,
<ol type="1">
<li>monotonicity: <span class="math inline">\(\forall A\subseteq
B\subseteq S, f(A)\leq f(B)\leq f(S)\)</span>,</li>
<li>locality: <span class="math inline">\(\forall A\subset B\subset
S\)</span>, consider any element <span class="math inline">\(x\in
S\)</span>, if <span class="math inline">\(f(A)=f(B)=f(A+x)\)</span>,
then <span class="math inline">\(f(A)=f(B+x)\)</span>.</li>
</ol>
</div>
<p></p>
Now there are some important concrete problem in the intersections.
<h3 data-number="2.3.1" id="euclidean-one-centre-problem"><span class="header-section-number">2.3.1</span> Euclidean one-centre
problem</h3>
<div class="theorem-environment Problem" data-index="5" type="Problem" title="Euclidean one-centre problem">
<span class="theorem-header"><span class="type">Problem</span><span class="index">5</span><span class="name">Euclidean one-centre
problem</span></span>
<p></p>
Given <span class="math inline">\(n\)</span> points <span class="math inline">\(V=\{v_1,\dots, v_n\}\)</span> in <span class="math inline">\(\R^d\)</span>, with weights <span class="math inline">\(w_1,\dots,w_n\)</span>, find a point in <span class="math inline">\(\R^d\)</span> which has the minimal of the maximum
weighted distance to all points in <span class="math inline">\(V\)</span>, that is, compute <span class="math inline">\(\min_x \max_{i} w_i^2(v_i-x)^2\)</span>.
</div>
<p></p>
Dyer showed that this problem can be considered as a multidimensional
search problem (in <span class="math inline">\(\R^{d+1}\)</span>) in
<span class="citation" data-cites="dyer_multidimensional_1986">[<a href="#ref-dyer_multidimensional_1986" role="doc-biblioref">6</a>]</span>. The conversion is not easy and not
intuitive. Das et al. claimed that this problem is a LP-type problem
with some additional constraints in <a href="I%20didn't%20read%20this%20carefully,%20it%20seems%20that%20they%20made%20the%20claim%20in%20the%20introduction%20but%20have%20never%20proven%20it"><span class="citation" data-cites="das_linear_2020">[<span>7</span>]</span></a>. It is still
unknown whether it is possible to formulate the weighted Euclidean
one-centre problem in <span class="math inline">\(\R^d\)</span> as a
LP-type problem with combinatorial dimension <span class="math inline">\(O(d)\)</span> (which is quite surprising…)
<h3 data-number="2.3.2" id="minimizing-the-sum-of-some-pwl-convex-functionsmy-problem"><span class="header-section-number">2.3.2</span> Minimizing the sum of some
pwl convex functions(my problem)</h3>
<p></p>
see <a href="#probpwl">above</a> for the definition.
<p></p>
Clearly this is a minimax parametric optimization problem. Zemel also
showed this is a multidimensional search problem with dimension <span class="math inline">\(d\)</span>. We want to know that if this is a
LP-type problem with combinatorial dimension <span class="math inline">\(O(d)\)</span>…
<p></p>
It seems that recognizing LP-type is hard. A <a href="https://ics.uci.edu/~eppstein/164/lecture10.pdf">lecture</a> on
LP-type problems by David Eppstein.
<hr />
<p></p>
Here are some materials for Low dimension LP:
<ul>
<li>chapter 20 of <a href="https://sarielhp.org/book/"><em>Geometric
Approximation Algorithms</em></a> by Sariel Har-Peled. <a href="https://sarielhp.org/book/chapters/lp.pdf" class="uri">https://sarielhp.org/book/chapters/lp.pdf</a></li>
<li>the fastest deterministic algorithm for this problem <span class="citation" data-cites="chan_improved_nodate">[<a href="#ref-chan_improved_nodate" role="doc-biblioref">8</a>]</span></li>
<li>my <a href="../../pdfs/LowdimLP-Seidel.pdf">slides</a> on Seidel’s <span class="math inline">\(O(d!n)\)</span> algorithm</li>
</ul>
<h1 class="unnumbered" id="bibliography">References</h1>
<div id="refs" class="references csl-bib-body" data-entry-spacing="0" role="list">
<div id="ref-grohe_dimension_2014" class="csl-entry" role="listitem">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">M.
Grohe, K. Kersting, M. Mladenov, E. Selman, Dimension
<span>Reduction</span> via <span>Colour</span> <span>Refinement</span>,
in: <em>Algorithms - <span>ESA</span> 2014</em>, Springer Berlin
Heidelberg, Berlin, Heidelberg, 2014: pp. 505–516.</div>
</div>
<div id="ref-cardon_partitioning_1982" class="csl-entry" role="listitem">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">A.
Cardon, M. Crochemore, Partitioning a graph in
<span>O</span>(<span>AlogV</span>), <em>Theoretical Computer
Science</em>. 19 (1982) 85–98 <a href="https://doi.org/10.1016/0304-3975(82)90016-0">10.1016/0304-3975(82)90016-0</a>.</div>
</div>
<div id="ref-paige_three_1987" class="csl-entry" role="listitem">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">R.
Paige, R.E. Tarjan, Three <span>Partition</span> <span>Refinement</span>
<span>Algorithms</span>, <em>SIAM Journal on Computing</em>. 16 (1987)
973–989 <a href="https://doi.org/10.1137/0216062">10.1137/0216062</a>.</div>
</div>
<div id="ref-berkholz_tightbound_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">C.
Berkholz, P. Bonsma, M. Grohe, Tight lower and upper bounds for the
complexity of canonical colour refinement, <em>Theor. Comp. Sys.</em> 60
(2017) 581–614 <a href="https://doi.org/10.1007/s00224-016-9686-0">10.1007/s00224-016-9686-0</a>.</div>
</div>
<div id="ref-kiefer_et_alicalp20" class="csl-entry" role="listitem">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">S.
Kiefer, B.D. McKay, <span class="nocase">The Iteration Number of Colour
Refinement</span>, in: <em>47th International Colloquium on Automata,
Languages, and Programming (ICALP 2020)</em>, Schloss Dagstuhl –
Leibniz-Zentrum f<span>ü</span>r Informatik, Dagstuhl, Germany, 2020:
pp. 73:1–73:19 <a href="https://doi.org/10.4230/LIPIcs.ICALP.2020.73">10.4230/LIPIcs.ICALP.2020.73</a>.</div>
</div>
<div id="ref-dyer_multidimensional_1986" class="csl-entry" role="listitem">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">M.E. Dyer, On a <span>Multidimensional</span>
<span>Search</span> <span>Technique</span> and <span>Its</span>
<span>Application</span> to the <span>Euclidean</span>
<span>One</span>-<span>Centre</span> <span>Problem</span>, <em>SIAM
Journal on Computing</em>. 15 (1986) 725–738 <a href="https://doi.org/10.1137/0215052">10.1137/0215052</a>.</div>
</div>
<div id="ref-das_linear_2020" class="csl-entry" role="listitem">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">S.
Das, A. Nandy, S. Sarvottamananda, Linear time algorithms for
<span>Euclidean</span> 1-center in <span><span class="math inline">\(\R^d\)</span></span> with non-linear convex
constraints, <em>Discrete Applied Mathematics</em>. 280 (2020) 71–85 <a href="https://doi.org/10.1016/j.dam.2019.09.009">10.1016/j.dam.2019.09.009</a>.</div>
</div>
<div id="ref-chan_improved_nodate" class="csl-entry" role="listitem">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">T.M. Chan, Improved deterministic algorithms
for linear programming in low dimensions, <em>ACM Trans.
Algorithms</em>. 14 (2018) <a href="https://doi.org/10.1145/3155312">10.1145/3155312</a>.</div>
</div>
</div>
    </section>
</article>

        </main>

        <footer class="no-print">
            Site proudly generated by
            <a href="http://jaspervdj.be/hakyll">Hakyll</a>.
            <a href="https://github.com/congyu711/Hakyllsite">Source</a> on Github.
            License <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0 </a> <img src="../../images/ccbysa.png" alt="Creative Commons License" style="height: 12px; vertical-align: baseline;">

        </footer>
    </div>
</body>

</html>