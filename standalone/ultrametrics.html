<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="googlebot" content="noindex">
    <title>Ultrametric notes</title>
    <link rel="stylesheet" href="../css/fonts.css" />
    <link rel="stylesheet" href="../css/default.css" />
    <link rel="stylesheet" href="../css/pygentize.css" />
    <link rel="stylesheet" href="../css/chao-theorems.css">
    <link rel="stylesheet" href="../css/sidenotes.css">
    <script defer src="../css/pangu.simple.js"></script>
    <script>
        // page title
        document.addEventListener("DOMContentLoaded", function () {
            const hostname = window.location.hostname;
            document.title = document.title + " | " + hostname;
        });

        // pangu
        document.addEventListener('DOMContentLoaded', () => {
            pangu.autoSpacingPage();
        });

        // mathjax
        MathJax = {
            options: {
                menuOptions: {
                    settings: {
                        enrich: false,        // true to enable semantic-enrichment
                        collapsible: false,   // true to enable collapsible math
                        speech: false,        // true to enable speech generation
                        braille: false,       // true to enable Braille generation
                        assistiveMml: false,  // true to enable assistive MathML
                    }
                },
                enableMenu: false
            },
            output: {
                font: 'mathjax-fira',
                fontURL: '/mathjax-fira-font'
            },
            tex: {
                macros: {
                    floor: ["{\\left\\lfloor #1 \\right\\rfloor}", 1],
                    ceil: ["{\\left\\lceil #1 \\right\\rceil}", 1],
                    set: ["{\\left\\{ #1 \\right\\}}", 1],
                    norm: ["{\\left\\| #1 \\right\\|}", 1],
                    F: "{\\mathbb F}",
                    R: "{\\mathbb R}",
                    C: "{\\mathbb C}",
                    Z: "{\\mathbb Z}",
                    e: "{\\varepsilon}",
                    mex: "\\mathop{\\operatorname{mex}}",
                    lcm: "\\mathop{\\operatorname{lcm}}",
                    dist: "\\mathop{\\operatorname{dist}}",
                    poly: "\\mathop{\\operatorname{poly}}",
                    polylog: "\\mathop{\\operatorname{polylog}}",
                    span: "\\mathop{\\operatorname{span}}",
                }
            }
        };
    </script>
    <script defer src="../mathjax/tex-chtml.js"></script>

</head>

<body>
    <div class="navbar-space">
        
        <!-- A table of contents on the left side, but only for screens
                that are big enough -->
        <div id="contents-big">
            <p class="mini-header">Contents <a id="up-arrow" href="#">↑</a></p>
            <ul>
<li><a href="#ultrametrics">ultrametrics</a>
<ul>
<li><a href="#exact-c-hst">exact <span class="math inline">\(c\)</span>-HST</a></li>
</ul></li>
<li><a href="#lp-rounding">LP rounding</a></li>
<li><a href="#todo">TODO</a></li>
</ul>
        </div>
        
    </div>
    <div class="text-space">
        <main role="main">
            <h1 class="pagetitle">Ultrametric notes</h1>
            <article>
                <section class="subtitle">
                    
                    Probabilistic embedding into ultrametrics
                    
                </section>
                <section class="header">
                    Posted on October 13, 2025
                    
                    by Yu Cong
                    
                </section>
                <section>
                    <p></p>
<a href="https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.APPROX/RANDOM.2023.2" class="uri">https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.APPROX/RANDOM.2023.2</a>
<h1 data-number="1" id="ultrametrics"><span class="header-section-number">1</span> ultrametrics</h1>
<div class="theorem-environment Definition" data-index="1" type="Definition" title="ultrametrics">
<span class="theorem-header"><span class="type">Definition</span><span class="index">1</span><span class="name">ultrametrics</span></span>
<p></p>
A metric space <span class="math inline">\((X,d)\)</span> is a
ultrametric if it satisfies the strong triangle inequality: <span class="math display">\[
    d(x,y)\leq \max\{d(x,z),d(z,y)\} \quad \forall x,y,z\in X
\]</span>
</div>
<p></p>
Ultrametric is a special case of tree metric. To see this, consider the
equivalence relation <span class="math inline">\(x \sim_{\leq r}
y\)</span> if <span class="math inline">\(d(x,y)\leq r\)</span>. For
each fixed <span class="math inline">\(r\)</span> there will be many
equivalent classes. We collect all equivalent class for all possible
<span class="math inline">\(r\)</span>. Let this collection of subsets
be <span class="math inline">\(L\)</span>. Note that we dont really have
to consider all values of <span class="math inline">\(r\)</span> but
only smallest <span class="math inline">\(r\)</span> such that the set
of equivalent classes changes.
<div class="theorem-environment Observation" data-index="2" type="Observation">
<span class="theorem-header"><span class="type">Observation</span><span class="index">2</span></span>
<p></p>
<span class="math inline">\(L\)</span> is laminar.
</div>
<p></p>
Now we have a tree-like structure. The root of the tree is the unique
equivalent class of <span class="math inline">\(\sim_{\leq \max
d(x,y)}\)</span>. The leaves will be equivalent classes of <span class="math inline">\(\sim_{\leq 0}\)</span>, i.e., singleton of
elements in <span class="math inline">\(X\)</span>. Then the laminar
strucuture of our collection <span class="math inline">\(L\)</span>
naturally forms a tree.
<p></p>
Note that
<ol class="example" type="1">
<li>every leaf in this tree has the same height.</li>
<li>the LCA of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> represents a equivalent class of <span class="math inline">\(\sim_{\leq d(x,y)}\)</span>.</li>
</ol>
<p></p>
We have to decide the edge weights. Let <span class="math inline">\(e\)</span> be an edge between nodes <span class="math inline">\(u\)</span> and <span class="math inline">\(v\)</span> which are some equivalent class of
<span class="math inline">\(\sim_{\leq a}\)</span> and <span class="math inline">\(\sim_{\leq b}\)</span>. Then the weight of this
edge is <span class="math inline">\(\frac{1}{2}(a-b)\)</span> (assuming
<span class="math inline">\(a\geq b\)</span>).
<p></p>
Now as (2) shows, the distance of leaves in the tree is <span class="math display">\[\begin{equation*}
\begin{aligned}
    d_T(x,y)&amp;=d_T(\mathop{\mathrm{LCA}}(x,y),x) +
d_T(\mathop{\mathrm{LCA}}(x,y),y)\\
            &amp;=\frac{1}{2}(d(x,y) -0)+\frac{1}{2}(d(x,y) -0)\\
            &amp;=d(x,y)
\end{aligned}
\end{equation*}\]</span>
<p></p>
Now i guess we have invented the so-called <em>Hierarchically Separated
Trees</em> (HST). Any ultrametric can be converted into a HST in this
way.
<h2 data-number="1.1" id="exact-c-hst"><span class="header-section-number">1.1</span> exact <span class="math inline">\(c\)</span>-HST</h2>
<p></p>
In the paper the target ultrametrics are limited to a special kind
called exact <span class="math inline">\(c\)</span>-HST. Let <span class="math inline">\(c&gt;1\)</span> be a constant. For a tree node
<span class="math inline">\(u\)</span> which represents an equivalence
class of <span class="math inline">\(\sim_{\leq x}\)</span>, we write
<span class="math inline">\(level(u)\)</span> for <span class="math inline">\(x\)</span>. The tree structure is the same as HST
but the edge weight is <span class="math inline">\(w((u,v))=\frac{1}{2}({level(u)}-{level(v)})\)</span>.
Let <span class="math inline">\(x,y\)</span> be two leaves in a exact
<span class="math inline">\(c\)</span>-HST, then <span class="math inline">\(d(x,y)={level(\mathop{\mathrm{LCA}}(x,y))}\)</span>.
<p></p>
The following lemma shows that we only lose a constant factor in the
distortion when restricting the target space to exact <span class="math inline">\(c\)</span>-HSTs.
<div id="exactHST" class="theorem-environment Lemma" data-index="3" type="Lemma">
<span class="theorem-header"><span class="type">Lemma</span><span class="index">3</span></span>
<p></p>
Given a metric space and its embedding into a distribution over
ultrametrics with distortion <span class="math inline">\(\alpha\)</span>, there is an embedding into a
distribution over exact <span class="math inline">\(c\)</span>-HSTs with
distortion <span class="math inline">\(\alpha\cdot c\)</span>.
</div>
<p></p>
<strong>An intuitive but failed proof method</strong> We try to show
that any ultrametric can be embedded into an exact <span class="math inline">\(c\)</span>-HST with distortion <span class="math inline">\(c\)</span>. Proving the distortion can be reduced
to the following combinatorial problem. Given a sequence of <span class="math inline">\(n\)</span> strictly increasing numbers <span class="math inline">\(\{a_i\}_{i\in [n]}\)</span>, find another sequence
<span class="math inline">\(c^{x_1},\dots, c^{x_n}\)</span> where <span class="math inline">\(x_i\leq x_j\)</span> for all <span class="math inline">\(i&lt;j\)</span>, such that <span class="math inline">\(\max_i \frac{a_i}{c^{x_i}}\leq c \min_i
\frac{a_i}{c^{x_i}}\)</span>. Now one can see that this is not always
true for any fixed <span class="math inline">\(c\)</span>… so embedding
into a distribution may be important.
<h1 data-number="2" id="lp-rounding"><span class="header-section-number">2</span> LP rounding</h1>
<p></p>
The authors then focus on embedding a given metric space <span class="math inline">\((N,d)\)</span> into distribution ober exact
2-HSTs. By <a href="#exactHST" title="Lemma 3">Lemma 3</a> they lose a
2-factor in the optimal distortion. It’s safe to assume that <span class="math inline">\(\min_{x,y\in N}d(x,y)=1\)</span> and <span class="math inline">\(\max_{x,y\in N}d(x,y)=\Delta\)</span>. (Thus our
embedding is always expanding.)
<p></p>
Assume that we embed <span class="math inline">\((N,d)\)</span> into a
single 2-HST. (<span class="math inline">\(N\)</span> is the set of
leaves in the tree.) Consider nodes with the same level in the 2-HST.
Recall that each nodes represents a subset of <span class="math inline">\(N\)</span> and these sets form the equivalence
class of <span class="math inline">\(\sim_{\leq 2^{p}}\)</span> where
<span class="math inline">\(p\)</span> is the level. The height of the
tree is <span class="math inline">\(O(\log \Delta)\)</span>. Now
consider the distortion of this embedding. Let <span class="math inline">\(q\)</span> be the distortion and let <span class="math inline">\(\chi_{x,y}\in\set{0,1}\)</span> be an incidator
variable such that <span class="math inline">\(\chi_{x,y}=0\)</span> iff
<span class="math inline">\(x\sim y\)</span>. (we omit the subscripts if
there is no confusion.)
<p></p>
<span class="math display">\[
    \sum_{r=0}^{\log \Delta} r \cdot \chi_{x,y} \leq q\cdot d(x,y) \quad
\forall x,y\in X
\]</span>
<!-- For a fixed $r$, the equivalence relation $\sim$ defines a graph $(N,E)$ where $(u,v)\in E$ iff $u\sim v$ (equivalently, $d(u,v)\leq c^r$). -->
<p></p>
If we embed into a distribution of 2-HSTs, then the indicator variable
<span class="math inline">\(\chi\)</span> will become the probability
that <span class="math inline">\(x,y\)</span> are not in the same
eqivalence class.
<p></p>
This kind of LP-formulating technique goes back to the uniform labeling
LP of Jon Kleinberg and Eva Tardos (see their <a href="https://www.cs.cornell.edu/home/kleinber/focs99-mrf.pdf">JACM’02
paper</a>) which in turn is analogous to the multiway cut LP of
Călinescu (see this <a href="https://arxiv.org/pdf/1611.05530">IPCO’17
paper</a>). In all these problems we want to ‘label’ vertices in a graph
and only edges with different labels contribute to the solution.
<p></p>
A good property of embedding into 2-HSTs is we don’t require the
solution to integral. However, the main difficulty is that we need to
solve <span class="math inline">\(\log \Delta\)</span> labeling problems
and they are dependent. For example, if <span class="math inline">\(x,y\)</span> are not separated at level <span class="math inline">\(r\)</span>, they shouldn’t be separated at any
higher level; In a distribution of 2-HSTs, this means that the
probability of <span class="math inline">\(x\sim y\)</span> is
non-decreasing in the level.
<p></p>
With all these observation in mind, the LP seems intuitive.
<h1 data-number="3" id="todo"><span class="header-section-number">3</span> TODO</h1>
<ul>
<li>understand their LP.
<ul>
<li>connections to CKR relaxation. <a href="https://courses.grainger.illinois.edu/cs583/sp2018/Notes/multiwaycut-ckr.pdf">This
lecture notes</a> talks about interpretation of CKR relaxation via
geometric view on <span class="math inline">\(k\)</span>-simplex, via
strengthening metric relaxation and via Lovász extension of submodular
functions.</li>
<li>connections to LP hierarchies</li>
<li>why the optimal solution is not always a distribution of HSTs</li>
</ul></li>
<li>how to move from exact 2-HST to general HSTs?</li>
</ul>
                </section>
            </article>
        </main>
    </div>
</body>

</html>